{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1qowXuJtzT7h6dj_cZMiTgel5MktF_VVD",
      "authorship_tag": "ABX9TyOwc3aLHCWNxO1AJuOKblGl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Crazytiger0527/Study_Pytorch/blob/main/AI_HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AI HW#5-2"
      ],
      "metadata": {
        "id": "SRDhWBtNvEPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4zrS7ifHqCFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1aa93a-bad3-43b7-ea57-2e612afa4bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# sklearn 라이브러리에서 fetch_openml 함수를 이용하여 MNIST 데이터셋 로드\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# 'mnist_784' 데이터셋을 로드. 데이터셋의 버전은 version=1, 로드된 데이터를 캐시에 저장하여 재사용이 용이하게 함.\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "# 데이터셋에서 특성(이미지 픽셀 값)을 X에 할당.  255로 나누어 정규화를 수행\n",
        "X = mnist.data / 255.0\n",
        "# 데이터셋에서 타겟(숫자 레이블)을 y에 할당\n",
        "y = mnist.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 시각화하는 데 사용\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# MNIST 데이터셋의 첫 번째 이미지를 표시.\n",
        "# X.iloc[0].values.reshape(28, 28) : 첫 번째 이미지 데이터를 28x28 픽셀 크기로 재배열.\n",
        "# cmap='gray' : 이미지를 회색조로 표시하도록 지정.\n",
        "plt.imshow(X.iloc[0].values.reshape(28, 28), cmap='gray')\n",
        "# 이미지 화면에 출력\n",
        "plt.show()\n",
        "# 첫번째 이미지의 레이블 출력.\n",
        "print('이미지 레이블 : {}'.format(y[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "QrIl6v-LrwNU",
        "outputId": "2cccd96f-fe73-4ce9-a68b-b037e1682262"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이미지 레이블 : 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터셋을 학습용 데이터와 테스트용 데이터로 분할\n",
        "# test_size=1/7. : 전체 데이터셋의 약 1/7을 테스트 데이터로 사용\n",
        "# random_state=0 : 데이터 분할시 무작위성을 제어하기 위한 값\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7., random_state=0)\n",
        "\n",
        "# DataFrame을 NumPy 배열로 변환한 후 PyTorch Tensor로 변환\n",
        "X_train = torch.Tensor(X_train.values)\n",
        "X_test = torch.Tensor(X_test.values)\n",
        "\n",
        "# 레이블 데이터(y)를 정수로 변환하고 PyTorch Tensor로 변환\n",
        "y_train = torch.LongTensor(list(map(int,y_train)))\n",
        "y_test = torch.LongTensor(list(map(int,y_test)))\n",
        "\n",
        "# 학습 데이터셋과 테스트 데이터셋을 PyTorch의 TensorDataset으로 변환\n",
        "ds_train = TensorDataset(X_train, y_train)\n",
        "ds_test = TensorDataset(X_test, y_test)\n",
        "\n",
        "# DataLoader를 사용하여 배치 크기를 지정.\n",
        "# 학습 데이터는 셔플, 테스트 데이터는 셔플X\n",
        "# 이를 통해 모델 학습 시 미니배치 학습을 수행할 수 있음\n",
        "loader_train = DataLoader(ds_train, batch_size = 64, shuffle=True)\n",
        "loader_test = DataLoader(ds_test, batch_size = 64, shuffle=False)"
      ],
      "metadata": {
        "id": "M-ERikmYsQcX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP 모델 제작\n",
        "from torch import nn\n",
        "\n",
        "# nn.Sequential을 사용하여 신경망 레이어들을 순차적으로 정의\n",
        "model = nn.Sequential()\n",
        "\n",
        "# 첫 번째 선형 레이어(fc1)를 추가\n",
        "# 이 레이어는 입력 노드 784개(28*28 픽셀)와 출력 노드 100개를 가짐\n",
        "model.add_module('fc1', nn.Linear(28*28*1, 100))\n",
        "\n",
        "# 첫 번째 ReLU 활성화 함수(relu1)를 추가\n",
        "# ReLU는 비선형성을 도입하여 모델이 복잡한 패턴을 학습할 수 있게 도움\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "\n",
        "# 두 번째 선형 레이어(fc2)를 추가\n",
        "# 이 레이어는 입력 노드 100개와 출력 노드 100개를 가짐\n",
        "model.add_module('fc2', nn.Linear(100, 100))\n",
        "\n",
        "# 두 번째 ReLU 활성화 함수(relu2)를 추가\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "\n",
        "# 세 번째 선형 레이어(fc3)를 추가\n",
        "# 이 레이어는 입력 노드 100개와 출력 노드 10개를 가짐\n",
        "# 출력 노드의 수는 MNIST 데이터셋의 클래스 수(0-9)와 일치\n",
        "model.add_module('fc3', nn.Linear(100, 10))"
      ],
      "metadata": {
        "id": "IAIZ6po5t1pW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "# 교차 엔트로피 손실 함수를 정의\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam 최적화 알고리즘을 사용\n",
        "# model.parameters()는 모델의 모든 학습 가능한 매개변수를 가져옴\n",
        "# lr=0.01은 학습률(learning rate)을 0.01로 설정함.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "JSz28RbOw6wN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeGtb8aCsBR4",
        "outputId": "5d3f5af8-e0c0-4388-e5dd-6f0b5352a070"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train 함수는 주어진 epoch에 대해 모델 학습을 수행\n",
        "def train(epoch):\n",
        "    # 모델을 학습 모드로 설정합니다.\n",
        "    model.train()\n",
        "\n",
        "    # 학습 데이터 로더를 순회\n",
        "    for data, targets in loader_train:\n",
        "        # 모든 최적화된 변수의 그라디언트를 0으로 설정\n",
        "        # 이는 새로운 최적화 단계를 시작하기 전에 이전 단계의 그라디언트를 지우기 위함\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 모델에 데이터를 전달하여 예측을 수행\n",
        "        outputs = model(data)\n",
        "\n",
        "        # 예측 결과와 실제 타겟 값을 비교하여 손실을 계산\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # 손실에 대한 그라디언트를 역전파합니다. 이는 모델의 매개변수를 최적화하기 위해 필요\n",
        "        loss.backward()\n",
        "\n",
        "        # 최적화 알고리즘을 한 단계 실행합니다. 이는 모델의 가중치를 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "    # 현재 epoch의 학습이 완료되었음을 출력\n",
        "    print('epoch {}: 완료'.format(epoch))"
      ],
      "metadata": {
        "id": "ySEnACSjyl0X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(head):\n",
        "    # 모델을 평가(evaluation) 모드로 설정\n",
        "    # 이는 모든 학습 관련 연산을 비활성화(예: 드롭아웃).\n",
        "    model.eval()\n",
        "\n",
        "    # 정확하게 예측된 샘플의 수를 저장하기 위한 변수\n",
        "    correct = 0\n",
        "\n",
        "    # 그라디언트 계산을 비활성화\n",
        "    with torch.no_grad():\n",
        "        # 테스트 데이터 로더를 순회\n",
        "        for data, targets in loader_test:\n",
        "            # 모델에 데이터를 전달하여 예측을 수행\n",
        "            outputs = model(data)\n",
        "\n",
        "            # 가장 높은 값(최종 예측)을 가진 인덱스를 가져옴\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # 정확한 예측의 수를 누적\n",
        "            correct += predicted.eq(targets.data.view_as(predicted)).sum()\n",
        "\n",
        "    # 테스트 데이터셋의 전체 데이터 수를 가져옴\n",
        "    data_num = len(loader_test.dataset)\n",
        "\n",
        "    # 정확도를 계산하고 출력\n",
        "    print('accuracy = ', 100. * correct / data_num)"
      ],
      "metadata": {
        "id": "1Mn-23xTzFoi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epoch(반복횟수) 3\n",
        "for epoch in range(3):\n",
        "  train(epoch)\n",
        "  test('학습중')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHUAjypF0W1A",
        "outputId": "e4eb86e7-7467-4099-efaa-f1a5197e6886"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0: 완료\n",
            "accuracy =  tensor(95.2400)\n",
            "epoch 1: 완료\n",
            "accuracy =  tensor(95.4600)\n",
            "epoch 2: 완료\n",
            "accuracy =  tensor(95.1700)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I9akYpIsRSZv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AI HW5-3"
      ],
      "metadata": {
        "id": "bnI-Iyc7RSWu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn 라이브러리에서 fetch_openml 함수를 이용하여 MNIST 데이터셋 로드\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# 'mnist_784' 데이터셋을 로드. 데이터셋의 버전은 version=1, 로드된 데이터를 캐시에 저장하여 재사용이 용이하게 함.\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "# 데이터셋에서 특성(이미지 픽셀 값)을 X에 할당.\n",
        "X = mnist.data\n",
        "# 데이터셋에서 타겟(숫자 레이블)을 y에 할당\n",
        "y = mnist.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXN9nDAXu-am",
        "outputId": "97c86fb2-863d-4baf-c59d-047f8eff5257"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터셋을 학습용 데이터와 테스트용 데이터로 분할\n",
        "# test_size=1/7. : 전체 데이터셋의 약 1/7을 테스트 데이터로 사용\n",
        "# random_state=0 : 데이터 분할시 무작위성을 제어하기 위한 값\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7., random_state=0)\n",
        "\n",
        "# DataFrame을 NumPy 배열로 변환한 후 PyTorch Tensor로 변환\n",
        "X_train = torch.Tensor(X_train.values)\n",
        "X_test = torch.Tensor(X_test.values)\n",
        "\n",
        "# 레이블 데이터(y)를 정수로 변환하고 PyTorch Tensor로 변환\n",
        "y_train = torch.LongTensor(list(map(int,y_train)))\n",
        "y_test = torch.LongTensor(list(map(int,y_test)))"
      ],
      "metadata": {
        "id": "YN-3mnX2u-YG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# X_train과 X_test 텐서의 모양을 CNN 모델에 적합하게 변경\n",
        "# -1은 배치 크기를 나타내며, PyTorch가 자동으로 이 값을 계산\n",
        "# 1은 채널의 수를 나타내며, MNIST 데이터셋은 그레이스케일 이미지이므로 채널이 하나\n",
        "# 28, 28은 이미지의 높이와 너비\n",
        "X_train = X_train.view(-1,1,28,28).float()\n",
        "X_test = X_test.view(-1,1,28,28).float()\n",
        "\n",
        "# 텐서 모양 출력\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "# 학습 데이터셋과 테스트 데이터셋을 PyTorch의 TensorDataset으로 변환\n",
        "train = TensorDataset(X_train, y_train)\n",
        "test = TensorDataset(X_test, y_test)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "# DataLoader를 사용하여 배치 크기를 지정.\n",
        "# 학습 데이터는 셔플, 테스트 데이터는 셔플X\n",
        "# 이를 통해 모델 학습 시 미니배치 학습을 수행할 수 있음\n",
        "loader_train = DataLoader(train, batch_size = BATCH_SIZE, shuffle=True)\n",
        "loader_test = DataLoader(test, batch_size = BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyNoLJXnu-V-",
        "outputId": "39fd8d72-542b-41b5-9690-cb10f00c1f69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 1, 28, 28])\n",
            "torch.Size([10000, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 클래스 정의. nn.Module을 상속받아 PyTorch 모델을 구현\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        # 부모 클래스의 생성자를 호출\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫 번째 컨볼루션 레이어: 1개의 입력 채널(그레이스케일 이미지), 32개의 출력 채널, 5x5 커널\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        # 두 번째 컨볼루션 레이어: 32개의 입력 채널, 32개의 출력 채널, 5x5 커널\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
        "        # 세 번째 컨볼루션 레이어: 32개의 입력 채널, 64개의 출력 채널, 5x5 커널\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5)\n",
        "        # 첫 번째 완전 연결 레이어: 입력 특성 576개(3x3x64), 출력 특성 256개\n",
        "        self.fc1 = nn.Linear(3*3*64, 256)\n",
        "        # 두 번째 완전 연결 레이어: 입력 특성 256개, 출력 특성 10개 (10개의 클래스)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        # 손실 함수 및 최적화기 정의\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 첫 번째 컨볼루션 레이어 + ReLU 활성화 함수\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # 두 번째 컨볼루션 레이어 + 맥스풀링 + ReLU 활성화 함수\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        # 드롭아웃 적용\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        # 세 번째 컨볼루션 레이어 + 맥스풀링 + ReLU 활성화 함수\n",
        "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
        "        # 드롭아웃 적용\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        # 평탄화(Flatten) - 완전 연결 레이어에 입력하기 전에 형태 변환\n",
        "        x = x.view(-1, 3*3*64)\n",
        "        # 첫 번째 완전 연결 레이어 + ReLU 활성화 함수\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # 드롭아웃 적용\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # 두 번째 완전 연결 레이어\n",
        "        x = self.fc2(x)\n",
        "        # 로그-소프트맥스 함수를 사용하여 출력을 확률 분포로 변환\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "LMQCj9Mzu-Tv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit 함수는 모델과 학습 데이터 로더를 인자로 받아 모델을 학습시킴\n",
        "def fit(model, loader_train):\n",
        "    # 모델의 매개변수에 대해 Adam 최적화기를 설정\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    # 교차 엔트로피 손실 함수를 설정\n",
        "    error = nn.CrossEntropyLoss()\n",
        "    # 학습할 에포크 수를 설정\n",
        "    EPOCHS = 1\n",
        "    # 모델을 학습 모드로 설정\n",
        "    model.train()\n",
        "    # 에포크 수만큼 반복\n",
        "    for epoch in range(EPOCHS):\n",
        "        # 정확히 예측된 샘플의 수를 저장할 변수\n",
        "        correct = 0\n",
        "        # 배치 단위로 학습 데이터를 순회\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(loader_train):\n",
        "            # 배치 데이터를 PyTorch Variable로 변환\n",
        "            var_X_batch = Variable(X_batch).float()\n",
        "            var_y_batch = Variable(y_batch)\n",
        "            # 이전 그라디언트를 초기화\n",
        "            optimizer.zero_grad()\n",
        "            # 모델에 배치 데이터를 전달하여 출력을 계산\n",
        "            output = model(var_X_batch)\n",
        "            # 출력과 실제 타겟 사이의 손실을 계\n",
        "            loss = error(output, var_y_batch)\n",
        "            # 손실에 대한 그라디언트를 역전파\n",
        "            loss.backward()\n",
        "            # 최적화기를 사용하여 모델의 가중치를 업데이트\n",
        "            optimizer.step()\n",
        "            # 예측 결과를 계산\n",
        "            predicted = torch.max(output.data, 1)[1]\n",
        "            # 정확한 예측 수를 업데이트\n",
        "            correct += (predicted == var_y_batch).sum()\n",
        "            # 일정한 간격으로 학습 진행 상황을 출력\n",
        "            if batch_idx % 50 == 0:\n",
        "                print('에포크 : {} [{}/{}({:.0f}%)]\\t 손실함수 : {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
        "                    epoch, batch_idx, len(loader_train),\n",
        "                    100. * batch_idx / len(loader_train), loss.data,\n",
        "                    correct * 100. / (BATCH_SIZE * (batch_idx + 1))))"
      ],
      "metadata": {
        "id": "6IrXC3jHu-RW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate 함수는 모델을 인자로 받아 테스트 데이터셋에 대해 평가 진행\n",
        "def evaluate(model):\n",
        "    # 정확하게 예측된 샘플의 수를 저장하기 위한 변수\n",
        "    correct = 0\n",
        "    # 테스트 데이터셋을 순회\n",
        "    for test_imgs, test_labels in loader_test:\n",
        "        # 테스트 이미지들을 PyTorch Variable로 변환\n",
        "        test_imgs = Variable(test_imgs).float()\n",
        "        # 모델에 테스트 이미지를 전달하여 예측을 수행\n",
        "        output = model(test_imgs)\n",
        "        # 가장 높은 값(최종 예측)을 가진 인덱스를 가져옴\n",
        "        predicted = torch.max(output, 1)[1]\n",
        "        # 정확한 예측의 수를 누적\n",
        "        correct += (predicted == test_labels).sum()\n",
        "    # 전체 테스트 데이터셋에 대한 정확도를 계산하고 출력\n",
        "    print(\"테스트 데이터 정확도 : {:.3f}%\".format(float(correct) / (len(loader_test) * BATCH_SIZE)))"
      ],
      "metadata": {
        "id": "LyJ68C1au-O8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 인스턴스를 생성\n",
        "cnn = CNN()\n",
        "# 모델의 초기 성능을 평가(모델은 아직 학습되지 않음)\n",
        "evaluate(cnn)\n",
        "# 모델을 학습 데이터셋을 사용하여 학습\n",
        "fit(cnn, loader_train)\n",
        "# 모델을 평가 모드로 설정합니다. 이는 학습에 사용되는 특정 동작들(예: 드롭아웃)을 비활성화\n",
        "cnn.eval()\n",
        "# 학습된 모델의 성능을 다시 평가\n",
        "evaluate(cnn)\n",
        "# 테스트 데이터셋의 특정 샘플에 대한 모델의 예측을 수행\n",
        "index = 10\n",
        "data = X_test[index].view(-1, 1, 28, 28).float()\n",
        "output = cnn(data)\n",
        "# 해당 샘플에 대한 모델의 예측 결과를 출력\n",
        "print('{}번째 학습데이터의 테스트 결과 : {}'.format(index, output))\n",
        "# 모델이 가장 높은 확률을 가진 클래스를 예측값으로 선택\n",
        "_, predicted = torch.max(output, 1)\n",
        "# 예측된 클래스를 출력\n",
        "print(\"{}번째 데이터의 예측 : {}\".format(index, predicted.numpy()))\n",
        "# 실제 레이블을 출력\n",
        "print(\"실제 레이블 : {}\".format(y_test[index]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djz6A6lPu-Mz",
        "outputId": "35497374-0e5c-4d38-fa7f-39655c38f05f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 정확도 : 0.100%\n",
            "에포크 : 0 [0/1875(0%)]\t 손실함수 : 20.982010\t Accuracy:6.250%\n",
            "에포크 : 0 [50/1875(3%)]\t 손실함수 : 2.048203\t Accuracy:18.873%\n",
            "에포크 : 0 [100/1875(5%)]\t 손실함수 : 0.890816\t Accuracy:33.014%\n",
            "에포크 : 0 [150/1875(8%)]\t 손실함수 : 0.603484\t Accuracy:43.936%\n",
            "에포크 : 0 [200/1875(11%)]\t 손실함수 : 0.969049\t Accuracy:52.410%\n",
            "에포크 : 0 [250/1875(13%)]\t 손실함수 : 0.478824\t Accuracy:58.230%\n",
            "에포크 : 0 [300/1875(16%)]\t 손실함수 : 0.428750\t Accuracy:62.915%\n",
            "에포크 : 0 [350/1875(19%)]\t 손실함수 : 0.727131\t Accuracy:66.382%\n",
            "에포크 : 0 [400/1875(21%)]\t 손실함수 : 0.379134\t Accuracy:69.132%\n",
            "에포크 : 0 [450/1875(24%)]\t 손실함수 : 0.328618\t Accuracy:71.307%\n",
            "에포크 : 0 [500/1875(27%)]\t 손실함수 : 0.396366\t Accuracy:73.085%\n",
            "에포크 : 0 [550/1875(29%)]\t 손실함수 : 0.306091\t Accuracy:74.705%\n",
            "에포크 : 0 [600/1875(32%)]\t 손실함수 : 0.231129\t Accuracy:76.045%\n",
            "에포크 : 0 [650/1875(35%)]\t 손실함수 : 0.202085\t Accuracy:77.285%\n",
            "에포크 : 0 [700/1875(37%)]\t 손실함수 : 0.190990\t Accuracy:78.290%\n",
            "에포크 : 0 [750/1875(40%)]\t 손실함수 : 0.115450\t Accuracy:79.203%\n",
            "에포크 : 0 [800/1875(43%)]\t 손실함수 : 0.268436\t Accuracy:79.994%\n",
            "에포크 : 0 [850/1875(45%)]\t 손실함수 : 0.118664\t Accuracy:80.729%\n",
            "에포크 : 0 [900/1875(48%)]\t 손실함수 : 0.280563\t Accuracy:81.344%\n",
            "에포크 : 0 [950/1875(51%)]\t 손실함수 : 0.382166\t Accuracy:81.838%\n",
            "에포크 : 0 [1000/1875(53%)]\t 손실함수 : 0.107100\t Accuracy:82.365%\n",
            "에포크 : 0 [1050/1875(56%)]\t 손실함수 : 0.165055\t Accuracy:82.879%\n",
            "에포크 : 0 [1100/1875(59%)]\t 손실함수 : 0.552328\t Accuracy:83.333%\n",
            "에포크 : 0 [1150/1875(61%)]\t 손실함수 : 0.073233\t Accuracy:83.734%\n",
            "에포크 : 0 [1200/1875(64%)]\t 손실함수 : 0.305552\t Accuracy:84.138%\n",
            "에포크 : 0 [1250/1875(67%)]\t 손실함수 : 0.065327\t Accuracy:84.510%\n",
            "에포크 : 0 [1300/1875(69%)]\t 손실함수 : 0.101796\t Accuracy:84.819%\n",
            "에포크 : 0 [1350/1875(72%)]\t 손실함수 : 0.058658\t Accuracy:85.150%\n",
            "에포크 : 0 [1400/1875(75%)]\t 손실함수 : 0.118364\t Accuracy:85.446%\n",
            "에포크 : 0 [1450/1875(77%)]\t 손실함수 : 0.431026\t Accuracy:85.753%\n",
            "에포크 : 0 [1500/1875(80%)]\t 손실함수 : 0.194778\t Accuracy:86.003%\n",
            "에포크 : 0 [1550/1875(83%)]\t 손실함수 : 0.114543\t Accuracy:86.253%\n",
            "에포크 : 0 [1600/1875(85%)]\t 손실함수 : 0.081326\t Accuracy:86.481%\n",
            "에포크 : 0 [1650/1875(88%)]\t 손실함수 : 0.046758\t Accuracy:86.728%\n",
            "에포크 : 0 [1700/1875(91%)]\t 손실함수 : 0.094221\t Accuracy:86.923%\n",
            "에포크 : 0 [1750/1875(93%)]\t 손실함수 : 0.258391\t Accuracy:87.141%\n",
            "에포크 : 0 [1800/1875(96%)]\t 손실함수 : 0.334797\t Accuracy:87.320%\n",
            "에포크 : 0 [1850/1875(99%)]\t 손실함수 : 0.614298\t Accuracy:87.508%\n",
            "테스트 데이터 정확도 : 0.977%\n",
            "10번째 학습데이터의 테스트 결과 : tensor([[-9.7359e+00, -2.2085e-03, -8.3079e+00, -1.0906e+01, -7.7183e+00,\n",
            "         -9.8884e+00, -9.3161e+00, -7.3136e+00, -7.8319e+00, -8.3631e+00]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "10번째 데이터의 예측 : [1]\n",
            "실제 레이블 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dqveUVMzu-KR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
